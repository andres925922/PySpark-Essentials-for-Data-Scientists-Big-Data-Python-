{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ping\n"
     ]
    }
   ],
   "source": [
    "print(\"ping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# Libraries\n",
    "import numpy as np\n",
    "import pyspark as ps\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "import tensorflow as tf\n",
    "\n",
    "# Utils\n",
    "\n",
    "from utils import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://6ae4f917bc9c:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>TensorFlow</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fab718d36d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = Session(\"TensorFlow\")\n",
    "spark = session.session\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.addFile(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\"\n",
    ")\n",
    "spark.sparkContext.addFile(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "# Lets define some constants to help us later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema\n",
    "from pyspark.sql.types import StructField,StringType,IntegerType,StructType, FloatType\n",
    "\n",
    "schema = []\n",
    "for column in CSV_COLUMN_NAMES:\n",
    "    if column == 'Species':\n",
    "        schema.append(StructField(column, IntegerType(), True))\n",
    "    else:\n",
    "        schema.append(StructField(column, FloatType(), True))\n",
    "\n",
    "schema = StructType(fields=schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = spark.read.csv(\n",
    "    ps.SparkFiles.get(\"iris_training.csv\"), header = False, schema = schema\n",
    ").toPandas().tail(-1)\n",
    "\n",
    "dfeval = spark.read.csv(\n",
    "    ps.SparkFiles.get(\"iris_test.csv\"), header = False, schema = schema\n",
    ").toPandas().tail(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "1          6.4         2.8          5.6         2.2      2.0\n",
       "2          5.0         2.3          3.3         1.0      1.0\n",
       "3          4.9         2.5          4.5         1.7      2.0\n",
       "4          4.9         3.1          1.5         0.1      0.0\n",
       "5          5.7         3.8          1.7         0.3      0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2\n",
       "2    1\n",
       "3    2\n",
       "4    0\n",
       "5    0\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = dftrain.pop('Species').astype(int) # Remove the species column\n",
    "test_y = dfeval.pop('Species').astype(int)\n",
    "\n",
    "train_y.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_function(\n",
    "        features, \n",
    "        labels, \n",
    "        training=True, \n",
    "        batch_size=256):\n",
    "\n",
    "    def input_fn():\n",
    "        # Convert the inputs to a Dataset.\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "        # Shuffle and repeat if you are in training mode.\n",
    "        if training:  # If training is True\n",
    "            dataset = dataset.shuffle(1000).repeat() # Shuffle 1000 times \n",
    "        \n",
    "        return dataset.batch(batch_size)\n",
    "    return input_fn\n",
    "\n",
    "# instead of calling lambda: input_fn(*args) we define the function wrapped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# Feature columns describe how to use the input. We don't need the numerical of the previous input function because we're looking for the key values\n",
    "my_feature_columns = []\n",
    "\n",
    "for key in dftrain.keys(): #this code will loop through all of the keys in the dataset\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "\n",
    "clear_output()\n",
    "print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpb16n0w79\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpb16n0w79', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[30, 10],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=len(SPECIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monkey-patching AttributeError: module 'inspect' has no attribute 'getargspec'\n",
    "import inspect\n",
    "\n",
    "if not hasattr(inspect, 'getargspec'):\n",
    "    inspect.getargspec = inspect.getfullargspec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.11/site-packages/keras/src/optimizers/legacy/adagrad.py:93: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.11/site-packages/tensorflow_estimator/python/estimator/model_fn.py:250: EstimatorSpec.__new__ (from tensorflow_estimator.python.estimator.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.11/site-packages/tensorflow_estimator/python/estimator/estimator.py:1416: NanTensorHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.11/site-packages/tensorflow_estimator/python/estimator/estimator.py:1419: LoggingTensorHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.11/site-packages/tensorflow/python/training/basic_session_run_hooks.py:232: SecondOrStepTimer.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.11/site-packages/tensorflow_estimator/python/estimator/estimator.py:1456: CheckpointSaverHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.11/site-packages/tensorflow/python/training/monitored_session.py:579: StepCounterHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.11/site-packages/tensorflow/python/training/monitored_session.py:586: SummarySaverHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpb16n0w79/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.11/site-packages/tensorflow/python/training/monitored_session.py:1455: SessionRunArgs.__new__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.11/site-packages/tensorflow/python/training/monitored_session.py:1454: SessionRunContext.__init__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.11/site-packages/tensorflow/python/training/monitored_session.py:1474: SessionRunValues.__new__ (from tensorflow.python.training.session_run_hook) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:loss = 2.06677, step = 0\n",
      "INFO:tensorflow:global_step/sec: 38.7724\n",
      "INFO:tensorflow:loss = 1.3346524, step = 100 (2.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.5298\n",
      "INFO:tensorflow:loss = 1.0862215, step = 200 (2.802 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.9015\n",
      "INFO:tensorflow:loss = 0.951899, step = 300 (1.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.2407\n",
      "INFO:tensorflow:loss = 0.90058386, step = 400 (1.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.3697\n",
      "INFO:tensorflow:loss = 0.8437299, step = 500 (1.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.3066\n",
      "INFO:tensorflow:loss = 0.80808127, step = 600 (2.206 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 637 vs previous value: 637. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 28.6222\n",
      "INFO:tensorflow:loss = 0.7707493, step = 700 (3.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.4079\n",
      "INFO:tensorflow:loss = 0.7709757, step = 800 (3.392 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 801 vs previous value: 801. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 886 vs previous value: 886. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 27.0132\n",
      "INFO:tensorflow:loss = 0.73524874, step = 900 (3.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.5419\n",
      "INFO:tensorflow:loss = 0.7052742, step = 1000 (1.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.8362\n",
      "INFO:tensorflow:loss = 0.7093906, step = 1100 (1.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.6073\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1200 vs previous value: 1200. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:loss = 0.6942971, step = 1200 (1.903 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6902\n",
      "INFO:tensorflow:loss = 0.6855675, step = 1300 (4.694 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1344 vs previous value: 1344. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 35.8559\n",
      "INFO:tensorflow:loss = 0.6688461, step = 1400 (2.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.2197\n",
      "INFO:tensorflow:loss = 0.6544083, step = 1500 (3.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.8556\n",
      "INFO:tensorflow:loss = 0.6528567, step = 1600 (4.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 52.672\n",
      "INFO:tensorflow:loss = 0.6238003, step = 1700 (1.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.5665\n",
      "INFO:tensorflow:loss = 0.60568213, step = 1800 (3.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.4966\n",
      "INFO:tensorflow:loss = 0.5927853, step = 1900 (2.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.4151\n",
      "INFO:tensorflow:loss = 0.5883257, step = 2000 (1.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.4688\n",
      "INFO:tensorflow:loss = 0.5728096, step = 2100 (1.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.544\n",
      "INFO:tensorflow:loss = 0.55216354, step = 2200 (2.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2337\n",
      "INFO:tensorflow:loss = 0.55944794, step = 2300 (4.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.6756\n",
      "INFO:tensorflow:loss = 0.5459045, step = 2400 (2.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.3355\n",
      "INFO:tensorflow:loss = 0.5542605, step = 2500 (3.098 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.7613\n",
      "INFO:tensorflow:loss = 0.5305504, step = 2600 (3.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.7154\n",
      "INFO:tensorflow:loss = 0.5262012, step = 2700 (1.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.4926\n",
      "INFO:tensorflow:loss = 0.5141347, step = 2800 (2.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.5111\n",
      "INFO:tensorflow:loss = 0.51650274, step = 2900 (2.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.263\n",
      "INFO:tensorflow:loss = 0.5094297, step = 3000 (1.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.6024\n",
      "INFO:tensorflow:loss = 0.49493894, step = 3100 (1.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.1138\n",
      "INFO:tensorflow:loss = 0.49608877, step = 3200 (1.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1569\n",
      "INFO:tensorflow:loss = 0.48666257, step = 3300 (4.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.4059\n",
      "INFO:tensorflow:loss = 0.4819584, step = 3400 (2.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.9335\n",
      "INFO:tensorflow:loss = 0.48117426, step = 3500 (1.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.6117\n",
      "INFO:tensorflow:loss = 0.4750209, step = 3600 (1.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.0414\n",
      "INFO:tensorflow:loss = 0.48232386, step = 3700 (3.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.2342\n",
      "INFO:tensorflow:loss = 0.46417415, step = 3800 (3.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.8743\n",
      "INFO:tensorflow:loss = 0.45845956, step = 3900 (4.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2035\n",
      "INFO:tensorflow:loss = 0.45102295, step = 4000 (4.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.2929\n",
      "INFO:tensorflow:loss = 0.44172186, step = 4100 (3.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.6554\n",
      "INFO:tensorflow:loss = 0.4481182, step = 4200 (5.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.0792\n",
      "INFO:tensorflow:loss = 0.43387562, step = 4300 (2.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.8369\n",
      "INFO:tensorflow:loss = 0.446592, step = 4400 (4.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.2786\n",
      "INFO:tensorflow:loss = 0.4381121, step = 4500 (3.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.8775\n",
      "INFO:tensorflow:loss = 0.431906, step = 4600 (4.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6213\n",
      "INFO:tensorflow:loss = 0.44168818, step = 4700 (3.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.5581\n",
      "INFO:tensorflow:loss = 0.4295531, step = 4800 (3.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.5453\n",
      "INFO:tensorflow:loss = 0.42443484, step = 4900 (2.207 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpb16n0w79/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.42949522.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7fab46b69690>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Training the DNN model\n",
    "classifier.train(\n",
    "    # input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    input_fn = make_input_function(dftrain, train_y),\n",
    "    steps=5000)\n",
    "# We include a lambda to avoid creating an inner function previously\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-07-31T16:07:54\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.11/site-packages/tensorflow/python/training/evaluation.py:260: FinalOpsHook.__init__ (from tensorflow.python.training.basic_session_run_hooks) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.keras instead.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpb16n0w79/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 1.66886s\n",
      "INFO:tensorflow:Finished evaluation at 2023-07-31-16:07:55\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.8666667, average_loss = 0.4938505, global_step = 5000, loss = 0.4938505\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmpb16n0w79/model.ckpt-5000\n",
      "\n",
      "Test set accuracy: 0.867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) Test the DNN model\n",
    "eval_result = classifier.evaluate(\n",
    "    # input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "    input_fn = make_input_function(dfeval, test_y, training=False))\n",
    "# We include a lambda to avoid creating an inner function previously\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpb16n0w79/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "{'logits': array([ 0.17967242, -1.5329056 , -3.0539646 ], dtype=float32), 'probabilities': array([0.8197971 , 0.14789148, 0.03231139], dtype=float32), 'class_ids': array([0]), 'classes': array([b'0'], dtype=object), 'all_class_ids': array([0, 1, 2], dtype=int32), 'all_classes': array([b'0', b'1', b'2'], dtype=object)}\n",
      "Prediction is \"Setosa\" (82.0%)\n",
      "{'logits': array([-3.8053029, -2.2266154, -2.402877 ], dtype=float32), 'probabilities': array([0.10087115, 0.4890826 , 0.41004616], dtype=float32), 'class_ids': array([1]), 'classes': array([b'1'], dtype=object), 'all_class_ids': array([0, 1, 2], dtype=int32), 'all_classes': array([b'0', b'1', b'2'], dtype=object)}\n",
      "Prediction is \"Versicolor\" (48.9%)\n",
      "{'logits': array([-5.5088744, -2.9436083, -2.421028 ], dtype=float32), 'probabilities': array([0.02782886, 0.36188978, 0.61028135], dtype=float32), 'class_ids': array([2]), 'classes': array([b'2'], dtype=object), 'all_class_ids': array([0, 1, 2], dtype=int32), 'all_classes': array([b'0', b'1', b'2'], dtype=object)}\n",
      "Prediction is \"Virginica\" (61.0%)\n"
     ]
    }
   ],
   "source": [
    "# 3) Predict the Classification in DNN model\n",
    "def predict_input_fn(features, batch_size=256):\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "# Here is some example input and expected classes you can try above\n",
    "predict = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],  # for ['Setosa', 'Versicolor', 'Virginica']\n",
    "    'SepalWidth' : [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth' : [0.5, 1.5, 2.1],\n",
    "}\n",
    "\n",
    "predict_df = pd.DataFrame(\n",
    "    data = [\n",
    "        [5.1, 3.3, 1.7, 0.5],   # Setosa\n",
    "        [5.9, 3.0, 4.2, 1.5],   # Versicolor\n",
    "        [6.9, 3.1, 5.4, 2.1]    # Virginica\n",
    "    ],\n",
    "    columns=features\n",
    ")\n",
    "\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: predict_input_fn(predict_df))\n",
    "\n",
    "clear_output()\n",
    "\n",
    "for pred_dict in predictions:\n",
    "    print(pred_dict)\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
    "        SPECIES[class_id], 100 * probability))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
